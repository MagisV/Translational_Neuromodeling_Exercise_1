{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750506a2-f6a0-4c3f-bb49-95747b60f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Distributions, Random\n",
    "using Plots, LaTeXStrings\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3c84d",
   "metadata": {},
   "source": [
    "# Exercise 3: DCM for EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91003e",
   "metadata": {},
   "source": [
    "## Exercise 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75496476",
   "metadata": {},
   "source": [
    "In the convolution-based DCM for ERP formalism, the post-synaptic potential $v(t)$ arises from a convolution of the presynaptic firing $\\sigma(t)$ with a convolution kernel $h(t)$, i.e.\n",
    "\n",
    "$$\n",
    "v(t) = h(t) \\otimes \\sigma(t) \\;=\\; \\int_{-\\infty}^{t} h(t - \\tau)\\,\\sigma(\\tau)\\,d\\tau,\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "h(t) =\n",
    "\\begin{cases}\n",
    "H\\,\\kappa\\,t\\,e^{-\\kappa t}, & t \\ge 0, \\\\\n",
    "0, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "In this exercise, derive the generic second-order differential equations underlying the convolution-based DCM for EEG models:\n",
    "\n",
    "$$\n",
    "\\ddot{v}(t)\n",
    "= H \\,\\kappa\\,\\sigma(t)\n",
    "\\;-\\; 2\\,\\kappa\\,\\dot{v}(t)\n",
    "\\;-\\; \\kappa^2\\,v(t).\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "**Hint**: Use Leibniz’ rule for differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82893250",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. The General Leibniz Rule\n",
    "\n",
    "Suppose we have a function\n",
    "\n",
    "$$\n",
    "I(t) \\;=\\; \\int_{a(t)}^{b(t)} f\\bigl(t,\\tau\\bigr)\\,d\\tau,\n",
    "$$\n",
    "\n",
    "where $a(t)$ and $b(t)$ are time‐dependent limits. **Leibniz’ rule** states:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\bigl[I(t)\\bigr]\n",
    "\\;=\\;\n",
    "f\\bigl(t,b(t)\\bigr)\\,\\frac{d}{dt}b(t)\n",
    "\\;-\\;\n",
    "f\\bigl(t,a(t)\\bigr)\\,\\frac{d}{dt}a(t)\n",
    "\\;+\\;\n",
    "\\int_{a(t)}^{b(t)}\n",
    "\\frac{\\partial}{\\partial t}f\\bigl(t,\\tau\\bigr)\\,d\\tau.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Special Case: Lower Limit Constant, Upper Limit $t$\n",
    "\n",
    "A common **special case** is $a(t)=a$ (a constant) and $b(t)=t$. Then:\n",
    "\n",
    "- $\\frac{d}{dt}a(t)=0$\n",
    "- $\\frac{d}{dt}b(t)=1$\n",
    "\n",
    "Hence the formula simplifies to\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\Bigl(\\,\\int_{a}^{t} f\\bigl(t,\\tau\\bigr)\\,d\\tau\\Bigr)\n",
    "\\;=\\;\n",
    "f\\bigl(t,t\\bigr)\n",
    "\\;+\\;\n",
    "\\int_{a}^{t}\n",
    "\\frac{\\partial}{\\partial t}f\\bigl(t,\\tau\\bigr)\\,d\\tau.\n",
    "$$\n",
    "\n",
    "In our exercise, $a=-\\infty$ (a constant limit, albeit an improper one) and $b(t)=t$. We can thus use this special‐case form directly.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why the Special Case Applies to the Exercise\n",
    "\n",
    "In **Equation (1)** of the exercise, we have\n",
    "\n",
    "$$\n",
    "v(t)\n",
    "\\;=\\;\n",
    "\\bigl[h \\otimes \\sigma\\bigr](t)\n",
    "\\;=\\;\n",
    "\\int_{-\\infty}^{t}\n",
    "h\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau)\\,d\\tau.\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- The **lower limit** of integration is $-\\infty$, a constant.  \n",
    "- The **upper limit** is $t$.  \n",
    "\n",
    "Thus, we can apply the special‐case Leibniz rule by identifying\n",
    "\n",
    "$$\n",
    "f\\bigl(t,\\tau\\bigr)\n",
    "\\;=\\;\n",
    "h\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Differentiating $v(t)$ Twice & Rearranging\n",
    "\n",
    "### 4.1 First Derivative\n",
    "\n",
    "Applying the special‐case rule:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\Bigl(\\int_{-\\infty}^{t} h\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau)\\,d\\tau\\Bigr)\n",
    "\\;=\\;\n",
    "h\\bigl(t-t\\bigr)\\,\\sigma(t)\n",
    "\\;+\\;\n",
    "\\int_{-\\infty}^{t}\n",
    "\\frac{\\partial}{\\partial t}\\Bigl[h\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau)\\Bigr]\\,d\\tau.\n",
    "$$\n",
    "\n",
    "- The term $h\\bigl(t-t\\bigr)=h(0)$. In **Equation (2)**, $h(0)=H\\,\\kappa\\,(0)\\,e^{-\\,\\kappa\\cdot 0}=0$, so the boundary term vanishes.  \n",
    "- $\\sigma(\\tau)$ does not depend on $t$, hence we only differentiate $h\\bigl(t-\\tau\\bigr)$.  \n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\dot{v}(t)\n",
    "\\;=\\;\n",
    "\\int_{-\\infty}^{t}\n",
    "h'\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau)\\,d\\tau.\n",
    "$$\n",
    "\n",
    "### 4.2 Second Derivative\n",
    "\n",
    "Repeat:\n",
    "\n",
    "$$\n",
    "\\ddot{v}(t)\n",
    "\\;=\\;\n",
    "\\frac{d}{dt}\\Bigl[\\int_{-\\infty}^{t} h'\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau)\\,d\\tau\\Bigr]\n",
    "\\;=\\;\n",
    "h'\\bigl(t-t\\bigr)\\,\\sigma(t)\n",
    "\\;+\\;\n",
    "\\int_{-\\infty}^{t}\n",
    "\\frac{\\partial}{\\partial t}\\Bigl[h'\\bigl(t-\\tau\\bigr)\\Bigr]\\sigma(\\tau)\\,d\\tau.\n",
    "$$\n",
    "\n",
    "- Now $h'(0)=H\\,\\kappa$.  \n",
    "- Thus, the boundary term is $H\\,\\kappa\\,\\sigma(t)$.  \n",
    "\n",
    "Hence,\n",
    "\n",
    "$$\n",
    "\\ddot{v}(t)\n",
    "\\;=\\;\n",
    "\\int_{-\\infty}^{t}\n",
    "h''\\bigl(t-\\tau\\bigr)\\,\\sigma(\\tau)\\,d\\tau\n",
    "\\;+\\;\n",
    "H\\,\\kappa\\,\\sigma(t).\n",
    "$$\n",
    "\n",
    "### 4.3 Rearranging to Get **Equation (3)** using Laplace Transform\n",
    "\n",
    "#### 4.3.1 Take the Laplace Transform of $h(t)$\n",
    "\n",
    "Recall the (one‐sided) Laplace transform $\\mathcal{L}\\{f(t)\\}(s)$ is\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\\{f(t)\\}(s)\n",
    "\\;=\\;\n",
    "\\int_{0}^{\\infty}\n",
    "f(t)\\,e^{-st}\\,dt,\n",
    "$$\n",
    "\n",
    "for functions $f(t)$ supported on $t\\ge0$. Here, $h(t)$ is already zero for $t<0$, so\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\\bigl\\{h(t)\\bigr\\}(s)\n",
    "\\;=\\;\n",
    "\\int_{0}^{\\infty}\n",
    "\\bigl[H\\,\\kappa\\,t\\,e^{-\\kappa t}\\bigr]\n",
    "\\,e^{-st}\\,dt\n",
    "\\;=\\;\n",
    "H\\,\\kappa\n",
    "\\int_{0}^{\\infty}\n",
    "t\\,e^{-(\\kappa + s)\\,t}\\,dt.\n",
    "$$\n",
    "\n",
    "#### 4.3.2 Evaluate the Integral\n",
    "\n",
    "We recognize this as a standard Laplace integral:\n",
    "\n",
    "$$\n",
    "\\int_{0}^{\\infty}\n",
    "t\\,e^{-\\alpha t}\\,dt\n",
    "\\;=\\;\n",
    "\\frac{1}{\\alpha^2},\n",
    "\\quad\\text{for } \\alpha>0.\n",
    "$$\n",
    "\n",
    "Here, $\\alpha = \\kappa + s$, so\n",
    "\n",
    "$$\n",
    "\\int_{0}^{\\infty}\n",
    "t\\,e^{-(\\kappa + s)t}\\,dt\n",
    "\\;=\\;\n",
    "\\frac{1}{(\\kappa + s)^2}.\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\\bigl\\{h(t)\\bigr\\}(s)\n",
    "\\;=\\;\n",
    "H\\,\\kappa\n",
    "\\,\n",
    "\\frac{1}{(\\kappa + s)^2}.\n",
    "$$\n",
    "\n",
    "#### 4.3.3 Apply the ODE Operator in the Laplace Domain\n",
    "\n",
    "The left‐hand side of \n",
    "\n",
    "$$\n",
    "\\ddot{h}(t) + 2\\,\\kappa\\,\\dot{h}(t) + \\kappa^2\\,h(t)\n",
    "$$\n",
    "\n",
    "translates via the Laplace transform to\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\\{\\ddot{h}\\}(s)\n",
    "\\;+\\;\n",
    "2\\,\\kappa\\,\\mathcal{L}\\{\\dot{h}\\}(s)\n",
    "\\;+\\;\n",
    "\\kappa^2\\,\\mathcal{L}\\{h\\}(s).\n",
    "$$\n",
    "\n",
    "But recall the Laplace transform of $\\dot{h}(t)$ and $\\ddot{h}(t)$ (assuming $h(0)=0$ and $\\dot{h}(0)$ finite, which holds here):\n",
    "\n",
    "- $\\mathcal{L}\\{\\dot{h}\\}(s) = s\\,\\mathcal{L}\\{h\\}(s) - h(0)$, but $h(0)=0$, so it’s $s\\,\\mathcal{L}\\{h\\}(s).$\n",
    "- $\\mathcal{L}\\{\\ddot{h}\\}(s) = s^2\\,\\mathcal{L}\\{h\\}(s) - s\\,h(0) - \\dot{h}(0),$ but $h(0)=0$ and we can check $\\dot{h}(0)$ is also finite. For $h(0)=0$, typically we get $s^2\\,\\mathcal{L}\\{h\\}(s).$\n",
    "\n",
    "Thus, in the Laplace domain:\n",
    "\n",
    "$$\n",
    "\\bigl[s^2 + 2\\,\\kappa\\,s + \\kappa^2\\bigr]\n",
    "\\,\\mathcal{L}\\{h\\}(s).\n",
    "$$\n",
    "\n",
    "Plug in $\\mathcal{L}\\{h\\}(s) = \\frac{H\\,\\kappa}{(\\kappa + s)^2}$:\n",
    "\n",
    "$$\n",
    "\\bigl[s^2 + 2\\,\\kappa\\,s + \\kappa^2\\bigr]\n",
    "\\;\n",
    "\\frac{H\\,\\kappa}{(\\kappa + s)^2}\n",
    "\\;=\\;\n",
    "H\\,\\kappa\n",
    "\\;\n",
    "\\frac{(s + \\kappa)^2}{(\\kappa + s)^2}\n",
    "\\;=\\;\n",
    "H\\,\\kappa.\n",
    "$$\n",
    "\n",
    "#### 4.3.4 The Right‐Hand Side is the Laplace Transform of $H\\,\\kappa\\,\\delta(t)$\n",
    "\n",
    "We know $\\mathcal{L}\\{\\delta(t)\\}(s) = 1$, so $\\mathcal{L}\\{H\\,\\kappa\\,\\delta(t)\\}(s) = H\\,\\kappa$. Hence, in the $s$‐domain, we have\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\\Bigl\\{\\ddot{h}(t)\n",
    "+ 2\\,\\kappa\\,\\dot{h}(t)\n",
    "+ \\kappa^2\\,h(t)\\Bigr\\}\n",
    "\\;=\\;\n",
    "H\\,\\kappa,\n",
    "$$\n",
    "\n",
    "which implies in the $t$‐domain:\n",
    "\n",
    "$$\n",
    "\\ddot{h}(t)\n",
    "+ 2\\,\\kappa\\,\\dot{h}(t)\n",
    "+ \\kappa^2\\,h(t)\n",
    "\\;=\\;\n",
    "H\\,\\kappa\\,\\delta(t).\n",
    "$$\n",
    "\n",
    "\n",
    "Convolution with $\\sigma(t)$ then implies\n",
    "\n",
    "$$\n",
    "\\ddot{v}(t)\n",
    "+ 2\\,\\kappa\\,\\dot{v}(t)\n",
    "+ \\kappa^2\\,v(t)\n",
    "\\;=\\;\n",
    "H\\,\\kappa\\,\\sigma(t).\n",
    "$$\n",
    "\n",
    "Rewriting:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\ddot{v}(t)\n",
    "\\;=\\;\n",
    "H\\,\\kappa\\,\\sigma(t)\n",
    "\\;-\\;\n",
    "2\\,\\kappa\\,\\dot{v}(t)\n",
    "\\;-\\;\n",
    "\\kappa^2\\,v(t),\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05e821",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Coupled harmonic oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1713844",
   "metadata": {},
   "source": [
    "We will now try to better understand DCM for ERPs. This type of DCM is commonly used to infer on hidden parameters from EEG data and takes into account the causal interaction between neuronal cell populations (e.g. pyramidal cells, inhibitory interneurons, spiny stellate cells), with formalized dynamics. To understand these dynamics, we will look at a simpler variant, the harmonic oscillator (HO).\n",
    "\n",
    "Let us first define a harmonic oscillator that is driven by an external force u(t) with the following equation:\n",
    "\n",
    "$$\n",
    "\\ddot{x} = -f \\dot{x} - \\kappa^2 x + u(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d309a",
   "metadata": {},
   "source": [
    "### 3.2 a)\n",
    "Convert the second-order differential equation of the harmonic oscillator into a first-order linear system to obtain the form\n",
    "\n",
    "$$\n",
    "\\dot{\\vec{x}} = A \\vec{x} + \\vec{u}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42612e6e",
   "metadata": {},
   "source": [
    "Given the second-order differential equation:\n",
    "\n",
    "$$\n",
    "\\ddot{x} = -f \\dot{x} - \\kappa^2 x + u(t)\n",
    "$$\n",
    "\n",
    "We introduce new variables:\n",
    "\n",
    "$$\n",
    "x_1 = x\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_2 = \\dot{x}\n",
    "$$\n",
    "\n",
    "\n",
    "This leads to:\n",
    "\n",
    "$$\n",
    "\\dot{x}_1 = x_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{x}_2 = -f x_2 - \\kappa^2 x_1 + u(t)\n",
    "$$\n",
    "\n",
    "We rewrite the system in matrix form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 0 & 1 \\\\ -\\kappa^2 & -f \\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} +\n",
    "\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} u(t)\n",
    "$$\n",
    "\n",
    "This can be written as:\n",
    "\n",
    "$$\n",
    "\\dot{x} = A\\vec{x} + \\vec{u}(t)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 0 & 1 \\\\ -\\kappa^2 & -f \\end{bmatrix}, \\quad\n",
    "\\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}, \\quad\n",
    "\\vec{u}(t) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} u(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741ced5",
   "metadata": {},
   "source": [
    "### 3.2 b)\n",
    "Now we consider the problem of a coupled dynamic system. Here, the input $u(t)$ comes from the dynamics of a second HO $(z(t))$, i.e.\n",
    "\n",
    "$$\n",
    "u(t) = a z(t)\n",
    "$$\n",
    "\n",
    "With\n",
    "\n",
    "$$\n",
    "\\ddot{z} = -f_z \\dot{z} - \\kappa^2 z + u_z(t)\n",
    "$$\n",
    "\n",
    "Again, convert the problem into a system of equations, such that\n",
    "\n",
    "$$\n",
    "\\dot{\\vec{x}} = A \\vec{x} + \\vec{u}(t)\n",
    "$$\n",
    "\n",
    "What are the components of $A$ and $\\vec{u}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11650ef",
   "metadata": {},
   "source": [
    "The second harmonic oscillator follows the equation:\n",
    "\n",
    "$$\n",
    "\\ddot{z} = -f_z \\dot{z} - \\kappa_z^2 z + u_z(t)\n",
    "$$\n",
    "\n",
    "As previously, we define state variables.\n",
    "\n",
    "For the first oscillator ($x$-system):\n",
    "\n",
    "$$\n",
    "x_1 = x, \\quad x_2 = \\dot{x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{x}_1 = x_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{x}_2 = -f x_2 - \\kappa^2 x_1 + a z\n",
    "$$\n",
    "\n",
    "For the second oscillator ($z$-system):\n",
    "\n",
    "$$\n",
    "z_1 = z, \\quad z_2 = \\dot{z}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{z}_1 = z_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{z}_2 = -f_z z_2 - \\kappa_z^2 z_1 + u_z(t)\n",
    "$$\n",
    "\n",
    "Define the state vector:\n",
    "\n",
    "$$\n",
    "\\vec{x} =\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ z_1 \\\\ z_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The system equations can now be written in matrix form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\\\ \\dot{z}_1 \\\\ \\dot{z}_2 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "-\\kappa^2 & -f & a & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & -\\kappa_z^2 & -f_z\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ z_1 \\\\ z_2 \\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} u_z(t)\n",
    "$$\n",
    "\n",
    "From the equation:\n",
    "\n",
    "$$\n",
    "\\dot{\\vec{x}} = A \\vec{x} + \\vec{u}(t)\n",
    "$$\n",
    "\n",
    "We extract:\n",
    "\n",
    "Matrix $A$:\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "-\\kappa^2 & -f & a & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & -\\kappa_z^2 & -f_z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Input vector $u(t)$:\n",
    "\n",
    "$$\n",
    "\\vec{u}(t) =\n",
    "\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} u_z(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fb71d",
   "metadata": {},
   "source": [
    "### 3.2 c)\n",
    "Reconsider Eq. (3). Assume that\n",
    "\n",
    "$$\n",
    "\\sigma(t) = a \\cdot s(v_z(t)) + u(t)\n",
    "$$\n",
    "\n",
    "Where $v_z(t)$ are the dynamics of a different population (also described by Eq.(3)) and\n",
    "\n",
    "$$\n",
    "s(v) = \\frac{1}{1 + \\exp(-r v)} - \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "In the same line of thought as before, transform the system described by Eq. (3) into a system of first-order linear differential equations by linearizing $s(v)$ around $v = 0$. If you compare the resulting equation with the result in Exercise 2b: What is the analogy between the neural state equation of the DCM for ERP and the harmonic oscillator (How do the parameters/functions $a$, $\\kappa$ and $f$ map onto the (linearized) DCM for ERP equations)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86466bee",
   "metadata": {},
   "source": [
    "We start with the equation:\n",
    "\n",
    "$$\n",
    "\\ddot{v}(t) = H \\kappa \\sigma(t) - 2\\kappa \\dot{v}(t) - \\kappa^2 v(t)\n",
    "$$\n",
    "\n",
    "\n",
    "First, let's approximate $s(v)$ using linearization.\n",
    "\n",
    "To linearize around $v = 0$, we compute the Taylor series expansion of $s(v)$ at $v = 0$:\n",
    "\n",
    "$$\n",
    "s(v) \\approx s(0) + s'(0) v\n",
    "$$\n",
    "\n",
    "Since:\n",
    "\n",
    "$$\n",
    "s(0) = 0, \\quad s'(v) = \\frac{r e^{-r v}}{(1 + e^{-r v})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "s'(0) = \\frac{r}{4}\n",
    "$$\n",
    "\n",
    "Thus, for small $v$:\n",
    "\n",
    "$$\n",
    "s(v) \\approx \\frac{r}{4} v\n",
    "$$\n",
    "\n",
    "Then, let's substitute $\\sigma(t)$ using the linearized $s(v)$:\n",
    "\n",
    "$$\n",
    "\\sigma(t) \\approx a \\frac{r}{4} v_z(t) + u(t)\n",
    "$$\n",
    "\n",
    "Putting this into the original equation:\n",
    "\n",
    "$$\n",
    "\\ddot{v} + 2\\kappa \\dot{v} + \\kappa^2 v = H \\kappa \\left( a \\frac{r}{4} v_z + u \\right)\n",
    "$$\n",
    "\n",
    "Which simplifies to:\n",
    "\n",
    "$$\n",
    "\\ddot{v} + 2\\kappa \\dot{v} + \\kappa^2 v = H \\kappa a \\frac{r}{4} v_z + H \\kappa u\n",
    "$$\n",
    "\n",
    "Define state variables:\n",
    "\n",
    "$$\n",
    "v_1 = v, \\quad v_2 = \\dot{v}, \\quad v_{z1} = v_z, \\quad v_{z2} = \\dot{v}_z\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\dot{v}_1 = v_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{v}_2 = -2\\kappa v_2 - \\kappa^2 v_1 + H\\kappa a \\frac{r}{4} v_{z1} + H\\kappa u\n",
    "$$\n",
    "\n",
    "For $v_z$, we assume it follows the same second-order dynamics:\n",
    "\n",
    "$$\n",
    "\\dot{v}_{z1} = v_{z2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{v}_{z2} = -2\\kappa_z v_{z2} - \\kappa_z^2 v_{z1} + H_z \\kappa_z u_z\n",
    "$$\n",
    "\n",
    "Define the state vector:\n",
    "\n",
    "$$\n",
    "\\vec{x} =\n",
    "\\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_{z1} \\\\ v_{z2} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then, the matrix system equations become:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\dot{v}_1 \\\\ \\dot{v}_2 \\\\ \\dot{v}_{z1} \\\\ \\dot{v}_{z2} \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "-\\kappa^2 & -2\\kappa & H\\kappa a \\frac{r}{4} & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & -\\kappa_z^2 & -2\\kappa_z\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_{z1} \\\\ v_{z2} \\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} 0 \\\\ H\\kappa \\\\ 0 \\\\ H_z\\kappa_z \\end{bmatrix}\n",
    "\\begin{bmatrix} u \\\\ u_z \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b84696",
   "metadata": {},
   "source": [
    "**Comparison with the Harmonic Oscillator**:\n",
    "The structure of this system closely resembles the harmonic oscillator equations:\n",
    "\n",
    "- $\\kappa$ plays the role of the damping coefficient.\n",
    "- $\\kappa^2$ acts like a restoring force.\n",
    "- $H \\kappa u$ represents external driving forces.\n",
    "- $H \\kappa a \\frac{r}{v} v_z$ shows coupling between populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9759d43",
   "metadata": {},
   "source": [
    "### 3.2 d)\n",
    "Draw the connectivity diagram (sources and connections in DCM-style) of this configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1e0bd",
   "metadata": {},
   "source": [
    "## Exercise 3.3: parameter estimation and inference on network structure\n",
    "\n",
    "In this exercise, we will perform a reduced model inversion similar to how one could infer on the most likely modulation structure in an empirical question. For the solutions to exercises (a)-(c), please provide your code by filling in the missing cells in this notebook.\n",
    "\n",
    "Consider the following setup:\n",
    "$$\\dot{x} = Ax+Cu$$\n",
    "$$x(t) = 0, t<0$$\n",
    "\n",
    "with \n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "    0 & 1 & 0 & 0 \\\\ \n",
    "    -\\kappa_1^2 & -f_1 & a_f & 0 \\\\ \n",
    "    0 & 0 & 0 & 1 \\\\\n",
    "    a_b & 0 & -\\kappa_2^2 & -f_2 \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$$C = \\begin{bmatrix} \n",
    "    0 \\\\ 0 \\\\ 0 \\\\ c \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$$u(t) = N(t,\\mu,\\sigma)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c1e85",
   "metadata": {},
   "source": [
    "### a) Integration  (10 Points)\n",
    "Integrate the system described above over the interval $0 ≤ t ≤ 0.2s$. \n",
    "Use the following settings and verify, that the integrated states $x_1$ and $x_3$ correspond to the data *x_condition_1 in tn2023_ex3.csv*.\n",
    "\n",
    "$$\\kappa_1 = 80$$\n",
    "$$\\kappa_2 = f_1 = f_2 = 50$$\n",
    "$$a_f = 3000$$\n",
    "$$a_b = 1000$$\n",
    "$$c = 1$$\n",
    "$$\\mu = 0.05$$\n",
    "$$\\sigma = 0.01$$\n",
    "\n",
    "Where $\\kappa_1$ and $\\kappa_2$ are defined in a population-specific manner, $a_f$ represents the weight of the forward connection, and $a_b$ the weight of the backward connection.\n",
    "\n",
    "*Hint: You can use any integration scheme you like with adequate step-size. A simple Euler based integration scheme with $dt = 0.001s$ will work just fine.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30aa98",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `dt` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing Rmath in the current active module Main",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `dt` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name may be made accessible by importing Rmath in the current active module Main\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/studia/magisterka/uzh/1-semestr/translational-neuromodeling/tn-exercise/tn-ex-repo/ex-03/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X46sZmlsZQ==.jl:26"
     ]
    }
   ],
   "source": [
    "# SETTING UP THE SIMULATION\n",
    "# defining model settings & parameters\n",
    "dt = 0.001\n",
    "t = 0:dt:0.2\n",
    "κ1 = 80\n",
    "κ2 = 50\n",
    "f1 = 50\n",
    "f2 = 50\n",
    "af = 3000\n",
    "ab = 1000\n",
    "c = 1.0\n",
    "μ = 0.05\n",
    "o = 0.01\n",
    "\n",
    "# defining matrices\n",
    "A = [0 1 0 0; -κ1^2 -f1 af 0; 0 0 0 1; ab 0 -κ2^2 -f2];\n",
    "C = [0;0;0;c];\n",
    "\n",
    "# preforming pdf\n",
    "u = pdf.(Normal(μ, o), t)\n",
    "\n",
    "# Euler integration\n",
    "x = zeros(4, length(t))\n",
    "\n",
    "for i in 1:(length(t)-1)\n",
    "    dx = A * x[:, i] + C * u[i]\n",
    "    x[:, i+1] = x[:, i] + dt * (A * x[:,i] + C * u[i])\n",
    "end\n",
    "\n",
    "# COMPARING TO REFERENCE\n",
    "df = CSV.read(\"x_condition_1.csv\", DataFrame; header=false)\n",
    "X_ref = Matrix(df)\n",
    "\n",
    "# getting x1 and x3 from reference data\n",
    "x1_ref = X_ref[1, :]\n",
    "x3_ref = X_ref[3, :]\n",
    "\n",
    "# plotting simualted and reference x₁ and x₃\n",
    "plot(t, x[1, :], label=\"x₁(sim)\", lw=2)\n",
    "plot!(t, x[3, :], label=\"x₃(sim)\", lw=2, xlabel=\"Time (s)\", ylabel=\"States\")\n",
    "plot!(t, x1_ref, label=\"x₁ (ref)\", lw=2)\n",
    "plot!(t, x3_ref, label=\"x₃ (ref)\", lw=2, xlabel=\"Time (s)\", ylabel=\"States\")\n",
    "# note: the simulated and reference x1 and x3 overlap, so it looks like only the references have been plotted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be9a43",
   "metadata": {},
   "source": [
    "### b) Parameter identification (8 Points)\n",
    "When looking at *x_condition_2.csv*, it becomes apparent that something in the system has changed. \n",
    "\n",
    "In fact, we have changed one of the following parameter values: $\\kappa_1$, $\\kappa_2$, $a_f$, $a_b$. Try to find out which!\n",
    "Compare the four different hypotheses in terms of the residual sum of squares or explained variance\n",
    "\n",
    "$$v_E = 1 − \\frac{var(y − y_p)}{var(y)}$$\n",
    "\n",
    "Which model best explains the data? What is the ensuing parameter estimate?\n",
    "\n",
    "*Hint: You can use a simple grid-search over the parameters. The true model should at least reach 98% of explained variance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90145cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum explained variance: 1.0\n",
      "Maximum explained variance: 0.90284772498048\n",
      "Maximum explained variance: 0.9558169159758355\n",
      "Maximum explained variance: 0.900999738183213\n",
      "Optimal κ1: 100\n",
      "Variance for k1 = 100: 1.0\n"
     ]
    }
   ],
   "source": [
    "csv = CSV.read(\"x_condition_2.csv\", DataFrame; header=false)\n",
    "X_cond2 = Matrix(csv)\n",
    "\n",
    "# function to simulate the model (based on 3.3a)\n",
    "function simulate_model(κ1, κ2, af, ab; dt=0.001, t=0:0.001:0.2, μ=0.05, o=0.01, c=1.0)\n",
    "    A = [0 1 0 0; -κ1^2 -f1 af 0; 0 0 0 1; ab 0 -κ2^2 -f2];\n",
    "    C = [0;0;0;c];\n",
    "    u = pdf.(Normal(μ, o), t)\n",
    "    x = zeros(4, length(t))\n",
    "    for i in 1:(length(t)-1)\n",
    "        dx = A * x[:, i] + C * u[i]\n",
    "        x[:, i+1] = x[:, i] + dt * (A * x[:,i] + C * u[i])\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "\n",
    "# function to calculate explained variance\n",
    "function variance(y, y_hat)\n",
    "    return 1 - var(y .- y_hat) / var(y)\n",
    "end\n",
    "\n",
    "# grid search over k1 (originally 80)\n",
    "κ1_vals = 50:5:110\n",
    "k1_ver = Float64[]\n",
    "\n",
    "for κ1_test in κ1_vals\n",
    "    x_sim = simulate_model(κ1_test, 50, 3000, 1000)\n",
    "    ve = variance(X_cond2, x_sim)\n",
    "    push!(k1_ver, ve)\n",
    "end\n",
    "\n",
    "# grid search over k2 (originally 50)\n",
    "κ2_vals = 20:5:80\n",
    "k2_ver = Float64[]\n",
    "\n",
    "for κ2_test in κ2_vals\n",
    "    x_sim = simulate_model(80, κ2_test, 3000, 1000)\n",
    "    ve = variance(X_cond2, x_sim)\n",
    "    push!(k2_ver, ve)\n",
    "end\n",
    "\n",
    "# grid search over af (originally 3000)\n",
    "af_vals = 2000:100:4000\n",
    "af_ver = Float64[]\n",
    "\n",
    "for af_test in af_vals\n",
    "    x_sim = simulate_model(80, 50, af_test, 1000)\n",
    "    ve = variance(X_cond2, x_sim)\n",
    "    push!(af_ver, ve)\n",
    "end\n",
    "\n",
    "# grid search over ab (originally 1000)\n",
    "ab_vals = 0:100:2000\n",
    "ab_ver = Float64[]\n",
    "\n",
    "for ab_test in ab_vals\n",
    "    x_sim = simulate_model(80, 50, 3000, ab_test)\n",
    "    ve = variance(X_cond2, x_sim)\n",
    "    push!(ab_ver, ve)\n",
    "end\n",
    "\n",
    "println(\"Maximum explained variance: \", maximum(k1_ver))\n",
    "println(\"Maximum explained variance: \", maximum(k2_ver))\n",
    "println(\"Maximum explained variance: \", maximum(af_ver))\n",
    "println(\"Maximum explained variance: \", maximum(ab_ver))\n",
    "\n",
    "# the output from above reveals that the max explained verience (100%) occurs when changing k1\n",
    "# to get the values of k1 that give the max explained variance, we can use argmax\n",
    "κ1_vals[argmax(k1_ver)]\n",
    "println(\"Optimal κ1: \", κ1_vals[argmax(k1_ver)])\n",
    "\n",
    "# checking to ensure k1 = 100 gives the expected max varience (it does)\n",
    "test_sim = simulate_model(100, 50, 3000, 1000)\n",
    "ver = variance(X_cond2, test_sim)\n",
    "println(\"Variance for k1 = 100: \", ver)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60532866",
   "metadata": {},
   "source": [
    "The above computations show that changing k1 results in the a max explained variance of 100%, which points to this being the culprit parameter. We can then use argmax to find the value of k1 that results in such high varience, which outputs 100. Therefore, setting k1 to 100 is likely what results in the data observed in x_condition_2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c285a7",
   "metadata": {},
   "source": [
    "### c) Forward model (2 Points)\n",
    "We have told you to look at the output of states $x_1$ and $x_3$. What would be the analogy in terms of a leadfield matrix $L$, such that\n",
    "$$ y(t) = Lx(t)$$\n",
    "corresponds to the activity of these two states?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
